; Listing generated by Microsoft (R) Optimizing Compiler Version 18.00.40629.0 

	TITLE	C:\Users\Philip\Documents\GitHub\MollenOS\clib\src\string\memcpy.c
	.686P
	.XMM
	include listing.inc
	.model	flat

INCLUDELIB MSVCRT
INCLUDELIB OLDNAMES

PUBLIC	_CpuFeatEcx
PUBLIC	_CpuFeatEdx
_BSS	SEGMENT
_CpuFeatEcx DD	01H DUP (?)
_CpuFeatEdx DD	01H DUP (?)
_BSS	ENDS
PUBLIC	_memcpy
PUBLIC	_memcpy_sse
PUBLIC	_memcpy_mmx
; Function compile flags: /Ogtp
; File c:\users\philip\documents\github\mollenos\clib\src\string\memcpy.c
;	COMDAT _memcpy_mmx
_TEXT	SEGMENT
_mBytes$ = -8						; size = 4
_Dest$ = -4						; size = 4
_destination$ = 8					; size = 4
_Source$ = 12						; size = 4
_source$ = 12						; size = 4
_MmxLoops$ = 16						; size = 4
_count$ = 16						; size = 4
_memcpy_mmx PROC					; COMDAT

; 92   : {

  00000	55		 push	 ebp
  00001	8b ec		 mov	 ebp, esp
  00003	83 ec 08	 sub	 esp, 8

; 93   : 	/* Pointers */
; 94   : 	uint32_t *Dest = (uint32_t*)destination;
; 95   : 	uint32_t *Source = (uint32_t*)source;

  00006	8b 4d 0c	 mov	 ecx, DWORD PTR _source$[ebp]

; 96   : 
; 97   : 	/* Loop Count */
; 98   : 	uint32_t MmxLoops = count / 8;

  00009	8b 55 10	 mov	 edx, DWORD PTR _count$[ebp]
  0000c	8b 45 08	 mov	 eax, DWORD PTR _destination$[ebp]
  0000f	89 4d 0c	 mov	 DWORD PTR _Source$[ebp], ecx
  00012	8b ca		 mov	 ecx, edx
  00014	53		 push	 ebx
  00015	c1 e9 03	 shr	 ecx, 3

; 99   : 	uint32_t mBytes = count % 8;

  00018	83 e2 07	 and	 edx, 7
  0001b	56		 push	 esi
  0001c	57		 push	 edi
  0001d	89 45 fc	 mov	 DWORD PTR _Dest$[ebp], eax
  00020	89 4d 10	 mov	 DWORD PTR _MmxLoops$[ebp], ecx
  00023	89 55 f8	 mov	 DWORD PTR _mBytes$[ebp], edx

; 100  : 
; 101  : 	/* Assembly Train */
; 102  : 	_asm 
; 103  : 	{
; 104  : 		/* Setup Registers / Loop Prologue */
; 105  : 		pushad

  00026	60		 pushad

; 106  : 		mov		edi, [Dest]

  00027	8b 7d fc	 mov	 edi, DWORD PTR _Dest$[ebp]

; 107  : 		mov		esi, [Source]

  0002a	8b 75 0c	 mov	 esi, DWORD PTR _Source$[ebp]

; 108  : 		mov		ecx, [MmxLoops]

  0002d	8b 4d 10	 mov	 ecx, DWORD PTR _MmxLoops$[ebp]

; 109  : 		test	ecx, ecx

  00030	85 c9		 test	 ecx, ecx

; 110  : 		je		MmxRemain

  00032	74 11		 je	 SHORT $MmxRemain$4
$MmxLoop$5:

; 111  : 
; 112  : 	MmxLoop:
; 113  : 		movq	mm0, [esi]

  00034	0f 6f 06	 movq	 mm0, MMWORD PTR [esi]

; 114  : 		movq	[edi], mm0

  00037	0f 7f 07	 movq	 MMWORD PTR [edi], mm0

; 115  : 
; 116  : 		/* Increase Pointers */
; 117  : 		add esi, 8

  0003a	83 c6 08	 add	 esi, 8

; 118  : 		add edi, 8

  0003d	83 c7 08	 add	 edi, 8

; 119  : 
; 120  : 		/* Loop Epilogue */
; 121  : 		dec	ecx							      

  00040	49		 dec	 ecx

; 122  : 		jnz MmxLoop

  00041	75 f1		 jne	 SHORT $MmxLoop$5

; 123  : 
; 124  : 		/* Done, cleanup MMX */
; 125  : 		emms

  00043	0f 77		 emms
$MmxRemain$4:

; 126  : 
; 127  : 		/* Remainders */
; 128  : 	MmxRemain:
; 129  : 		mov ecx, [mBytes]

  00045	8b 4d f8	 mov	 ecx, DWORD PTR _mBytes$[ebp]

; 130  : 		test ecx, ecx

  00048	85 c9		 test	 ecx, ecx

; 131  : 		je MmxDone

  0004a	74 02		 je	 SHORT $MmxDone$6

; 132  : 
; 133  : 		/* Esi and Edi are already setup */
; 134  : 		rep movsb

  0004c	f3 a4		 rep	  movsb
$MmxDone$6:

; 135  : 
; 136  : 	MmxDone:
; 137  : 		popad

  0004e	61		 popad

; 138  : 	}
; 139  : 
; 140  : 	return destination;

  0004f	8b 45 08	 mov	 eax, DWORD PTR _destination$[ebp]

; 141  : }

  00052	5f		 pop	 edi
  00053	5e		 pop	 esi
  00054	5b		 pop	 ebx
  00055	8b e5		 mov	 esp, ebp
  00057	5d		 pop	 ebp
  00058	c3		 ret	 0
_memcpy_mmx ENDP
_TEXT	ENDS
; Function compile flags: /Ogtp
; File c:\users\philip\documents\github\mollenos\clib\src\string\memcpy.c
;	COMDAT _memcpy_sse
_TEXT	SEGMENT
_mBytes$ = -8						; size = 4
_Dest$ = -4						; size = 4
_destination$ = 8					; size = 4
_Source$ = 12						; size = 4
_source$ = 12						; size = 4
_SseLoops$ = 16						; size = 4
_count$ = 16						; size = 4
_memcpy_sse PROC					; COMDAT

; 18   : {

  00000	55		 push	 ebp
  00001	8b ec		 mov	 ebp, esp
  00003	83 ec 08	 sub	 esp, 8

; 19   : 	/* Pointers */
; 20   : 	uint32_t *Dest = (uint32_t*)destination;
; 21   : 	uint32_t *Source = (uint32_t*)source;

  00006	8b 4d 0c	 mov	 ecx, DWORD PTR _source$[ebp]

; 22   : 	
; 23   : 	/* Loop Count */
; 24   : 	uint32_t SseLoops = count / 16;

  00009	8b 55 10	 mov	 edx, DWORD PTR _count$[ebp]
  0000c	8b 45 08	 mov	 eax, DWORD PTR _destination$[ebp]
  0000f	89 4d 0c	 mov	 DWORD PTR _Source$[ebp], ecx
  00012	8b ca		 mov	 ecx, edx
  00014	53		 push	 ebx
  00015	c1 e9 04	 shr	 ecx, 4

; 25   : 	uint32_t mBytes = count % 16;

  00018	83 e2 0f	 and	 edx, 15			; 0000000fH
  0001b	56		 push	 esi
  0001c	57		 push	 edi
  0001d	89 45 fc	 mov	 DWORD PTR _Dest$[ebp], eax
  00020	89 4d 10	 mov	 DWORD PTR _SseLoops$[ebp], ecx
  00023	89 55 f8	 mov	 DWORD PTR _mBytes$[ebp], edx

; 26   : 
; 27   : 	/* Assembly Train */
; 28   : 	_asm 
; 29   : 	{
; 30   : 		/* Setup Registers / Loop Prologue */
; 31   : 		pushad

  00026	60		 pushad

; 32   : 		mov		edi, [Dest]

  00027	8b 7d fc	 mov	 edi, DWORD PTR _Dest$[ebp]

; 33   : 		mov		esi, [Source]

  0002a	8b 75 0c	 mov	 esi, DWORD PTR _Source$[ebp]

; 34   : 		mov		ecx, [SseLoops]

  0002d	8b 4d 10	 mov	 ecx, DWORD PTR _SseLoops$[ebp]

; 35   : 		test	ecx, ecx

  00030	85 c9		 test	 ecx, ecx

; 36   : 		je		SseRemain

  00032	74 30		 je	 SHORT $SseRemain$4

; 37   : 
; 38   : 		/* Test if buffers are 16 byte aligned */
; 39   : 		test si, 0xF

  00034	66 f7 c6 0f 00	 test	 si, 15			; 0000000fH

; 40   : 		jne UnalignedLoop

  00039	75 18		 jne	 SHORT $UnalignedLoop$5

; 41   : 		test di, 0xF

  0003b	66 f7 c7 0f 00	 test	 di, 15			; 0000000fH

; 42   : 		jne UnalignedLoop

  00040	75 11		 jne	 SHORT $UnalignedLoop$5
$AlignedLoop$6:

; 43   : 
; 44   : 	/* Aligned Loop */
; 45   : 	AlignedLoop:
; 46   : 		movaps	xmm0, [esi]

  00042	0f 28 06	 movaps	 xmm0, XMMWORD PTR [esi]

; 47   : 		movaps	[edi], xmm0

  00045	0f 29 07	 movaps	 XMMWORD PTR [edi], xmm0

; 48   : 
; 49   : 		/* Increase Pointers */
; 50   : 		add esi, 16

  00048	83 c6 10	 add	 esi, 16			; 00000010H

; 51   : 		add edi, 16

  0004b	83 c7 10	 add	 edi, 16			; 00000010H

; 52   : 
; 53   : 		/* Loop Epilogue */
; 54   : 		dec	ecx							      

  0004e	49		 dec	 ecx

; 55   : 		jnz AlignedLoop

  0004f	75 f1		 jne	 SHORT $AlignedLoop$6

; 56   : 		jmp	SseDone

  00051	eb 0f		 jmp	 SHORT $SseDone$7
$UnalignedLoop$5:

; 57   : 	
; 58   : 	/* Unaligned Loop */
; 59   : 	UnalignedLoop:
; 60   : 		movups	xmm0, [esi]

  00053	0f 10 06	 movups	 xmm0, XMMWORD PTR [esi]

; 61   : 		movups	[edi], xmm0

  00056	0f 11 07	 movups	 XMMWORD PTR [edi], xmm0

; 62   : 
; 63   : 		/* Increase Pointers */
; 64   : 		add esi, 16

  00059	83 c6 10	 add	 esi, 16			; 00000010H

; 65   : 		add edi, 16

  0005c	83 c7 10	 add	 edi, 16			; 00000010H

; 66   : 
; 67   : 		/* Loop Epilogue */
; 68   : 		dec	ecx							      

  0005f	49		 dec	 ecx

; 69   : 		jnz UnalignedLoop

  00060	75 f1		 jne	 SHORT $UnalignedLoop$5
$SseDone$7:

; 70   : 
; 71   : 	SseDone:
; 72   : 		/* Done, cleanup MMX */
; 73   : 		emms

  00062	0f 77		 emms
$SseRemain$4:

; 74   : 
; 75   : 		/* Remainders */
; 76   : 	SseRemain:
; 77   : 		mov ecx, [mBytes]

  00064	8b 4d f8	 mov	 ecx, DWORD PTR _mBytes$[ebp]

; 78   : 		test ecx, ecx

  00067	85 c9		 test	 ecx, ecx

; 79   : 		je CpyDone

  00069	74 02		 je	 SHORT $CpyDone$8

; 80   : 
; 81   : 		/* Esi and Edi are already setup */
; 82   : 		rep movsb

  0006b	f3 a4		 rep	  movsb
$CpyDone$8:

; 83   : 
; 84   : 	CpyDone:
; 85   : 		popad

  0006d	61		 popad

; 86   : 	}
; 87   : 
; 88   : 	return destination;

  0006e	8b 45 08	 mov	 eax, DWORD PTR _destination$[ebp]

; 89   : }

  00071	5f		 pop	 edi
  00072	5e		 pop	 esi
  00073	5b		 pop	 ebx
  00074	8b e5		 mov	 esp, ebp
  00076	5d		 pop	 ebp
  00077	c3		 ret	 0
_memcpy_sse ENDP
_TEXT	ENDS
; Function compile flags: /Ogtp
; File c:\users\philip\documents\github\mollenos\clib\src\string\memcpy.c
;	COMDAT _memcpy
_TEXT	SEGMENT
_destination$ = 8					; size = 4
_source$ = 12						; size = 4
_count$ = 16						; size = 4
_memcpy	PROC						; COMDAT

; 145  : {

  00000	55		 push	 ebp
  00001	8b ec		 mov	 ebp, esp

; 146  : 	/* Sanity */
; 147  : 	if(CpuFeatEcx == 0 && CpuFeatEdx == 0)

  00003	83 3d 00 00 00
	00 00		 cmp	 DWORD PTR _CpuFeatEcx, 0
  0000a	a1 00 00 00 00	 mov	 eax, DWORD PTR _CpuFeatEdx
  0000f	53		 push	 ebx
  00010	75 1c		 jne	 SHORT $LN12@memcpy
  00012	85 c0		 test	 eax, eax
  00014	75 18		 jne	 SHORT $LN12@memcpy

; 150  : 			mov	eax, 1

  00016	b8 01 00 00 00	 mov	 eax, 1

; 151  : 			cpuid

  0001b	0f a2		 cpuid

; 152  : 			mov	[CpuFeatEcx], ecx

  0001d	89 0d 00 00 00
	00		 mov	 DWORD PTR _CpuFeatEcx, ecx

; 153  : 			mov	[CpuFeatEdx], edx

  00023	89 15 00 00 00
	00		 mov	 DWORD PTR _CpuFeatEdx, edx

; 148  : 	{
; 149  : 		_asm {

  00029	a1 00 00 00 00	 mov	 eax, DWORD PTR _CpuFeatEdx
$LN12@memcpy:

; 154  : 		}
; 155  : 	}
; 156  : 
; 157  : 	//Can we use SSE?
; 158  : 	if(CpuFeatEdx & CPUID_FEAT_EDX_SSE)

  0002e	a9 00 00 00 02	 test	 eax, 33554432		; 02000000H
  00033	74 07		 je	 SHORT $LN11@memcpy
  00035	5b		 pop	 ebx

; 202  : 	}
; 203  : }

  00036	5d		 pop	 ebp

; 159  : 		return memcpy_sse(destination, source, count);

  00037	e9 00 00 00 00	 jmp	 _memcpy_sse
$LN11@memcpy:

; 160  : 	else if(CpuFeatEdx & CPUID_FEAT_EDX_MMX)

  0003c	a9 00 00 80 00	 test	 eax, 8388608		; 00800000H
  00041	74 07		 je	 SHORT $LN9@memcpy
  00043	5b		 pop	 ebx

; 202  : 	}
; 203  : }

  00044	5d		 pop	 ebp

; 161  : 		return memcpy_mmx(destination, source, count);

  00045	e9 00 00 00 00	 jmp	 _memcpy_mmx
$LN9@memcpy:

; 162  : 	else
; 163  : 	{
; 164  : 		char *dst = (char*)destination;

  0004a	8b 5d 08	 mov	 ebx, DWORD PTR _destination$[ebp]
  0004d	8b c3		 mov	 eax, ebx

; 165  : 		const char *src = (const char*)source;

  0004f	8b 55 0c	 mov	 edx, DWORD PTR _source$[ebp]
  00052	56		 push	 esi

; 166  : 		long *aligned_dst;
; 167  : 		const long *aligned_src;
; 168  : 
; 169  : 		/* If the size is small, or either SRC or DST is unaligned,
; 170  : 			then punt into the byte copy loop.  This should be rare.  */
; 171  : 		if (!TOO_SMALL(count) && !UNALIGNED (src, dst))

  00053	8b 75 10	 mov	 esi, DWORD PTR _count$[ebp]
  00056	83 fe 10	 cmp	 esi, 16			; 00000010H
  00059	72 56		 jb	 SHORT $LN3@memcpy
  0005b	8b cb		 mov	 ecx, ebx
  0005d	0b ca		 or	 ecx, edx
  0005f	f6 c1 03	 test	 cl, 3
  00062	75 4d		 jne	 SHORT $LN3@memcpy

; 172  : 		{
; 173  : 			aligned_dst = (long*)dst;

  00064	57		 push	 edi
  00065	8b fe		 mov	 edi, esi
  00067	c1 ef 04	 shr	 edi, 4
  0006a	8d 9b 00 00 00
	00		 npad	 6
$LL6@memcpy:

; 174  : 			aligned_src = (long*)src;
; 175  : 
; 176  : 			/* Copy 4X long words at a time if possible.  */
; 177  : 			while (count >= BIGBLOCKSIZE)
; 178  : 			{
; 179  : 				*aligned_dst++ = *aligned_src++;

  00070	8b 0a		 mov	 ecx, DWORD PTR [edx]

; 180  : 				*aligned_dst++ = *aligned_src++;
; 181  : 				*aligned_dst++ = *aligned_src++;
; 182  : 				*aligned_dst++ = *aligned_src++;
; 183  : 				count -= BIGBLOCKSIZE;

  00072	83 ee 10	 sub	 esi, 16			; 00000010H
  00075	89 08		 mov	 DWORD PTR [eax], ecx
  00077	8b 4a 04	 mov	 ecx, DWORD PTR [edx+4]
  0007a	89 48 04	 mov	 DWORD PTR [eax+4], ecx
  0007d	8b 4a 08	 mov	 ecx, DWORD PTR [edx+8]
  00080	89 48 08	 mov	 DWORD PTR [eax+8], ecx
  00083	8b 4a 0c	 mov	 ecx, DWORD PTR [edx+12]
  00086	83 c2 10	 add	 edx, 16			; 00000010H
  00089	89 48 0c	 mov	 DWORD PTR [eax+12], ecx
  0008c	83 c0 10	 add	 eax, 16			; 00000010H
  0008f	4f		 dec	 edi
  00090	75 de		 jne	 SHORT $LL6@memcpy

; 184  : 			}
; 185  : 
; 186  : 			/* Copy one long word at a time if possible.  */
; 187  : 			while (count >= LITTLEBLOCKSIZE)

  00092	83 fe 04	 cmp	 esi, 4
  00095	72 19		 jb	 SHORT $LN29@memcpy
  00097	8b fe		 mov	 edi, esi
  00099	c1 ef 02	 shr	 edi, 2
  0009c	8d 64 24 00	 npad	 4
$LL4@memcpy:

; 188  : 			{
; 189  : 				*aligned_dst++ = *aligned_src++;

  000a0	8b 0a		 mov	 ecx, DWORD PTR [edx]

; 190  : 				count -= LITTLEBLOCKSIZE;

  000a2	83 ee 04	 sub	 esi, 4
  000a5	89 08		 mov	 DWORD PTR [eax], ecx
  000a7	83 c2 04	 add	 edx, 4
  000aa	83 c0 04	 add	 eax, 4
  000ad	4f		 dec	 edi
  000ae	75 f0		 jne	 SHORT $LL4@memcpy
$LN29@memcpy:
  000b0	5f		 pop	 edi
$LN3@memcpy:

; 191  : 			}
; 192  : 
; 193  : 			/* Pick up any residual with a byte copier.  */
; 194  : 			dst = (char*)aligned_dst;
; 195  : 			src = (char*)aligned_src;
; 196  : 		}
; 197  : 
; 198  : 		while (count--)

  000b1	85 f6		 test	 esi, esi
  000b3	74 0e		 je	 SHORT $LN20@memcpy
  000b5	2b d0		 sub	 edx, eax
$LL2@memcpy:

; 199  : 		*dst++ = *src++;

  000b7	8a 0c 02	 mov	 cl, BYTE PTR [edx+eax]
  000ba	8d 40 01	 lea	 eax, DWORD PTR [eax+1]
  000bd	88 48 ff	 mov	 BYTE PTR [eax-1], cl
  000c0	4e		 dec	 esi
  000c1	75 f4		 jne	 SHORT $LL2@memcpy
$LN20@memcpy:
  000c3	5e		 pop	 esi

; 200  : 
; 201  : 		return destination;

  000c4	8b c3		 mov	 eax, ebx
  000c6	5b		 pop	 ebx

; 202  : 	}
; 203  : }

  000c7	5d		 pop	 ebp
  000c8	c3		 ret	 0
_memcpy	ENDP
_TEXT	ENDS
END
