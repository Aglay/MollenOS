; Listing generated by Microsoft (R) Optimizing Compiler Version 18.00.31101.0 

	TITLE	C:\Users\Philip\Documents\GitHub\MollenOS\clib\src\string\memmove.c
	.686P
	.XMM
	include listing.inc
	.model	flat

INCLUDELIB MSVCRT
INCLUDELIB OLDNAMES

PUBLIC	_memmove
; Function compile flags: /Ogtp
; File c:\users\philip\documents\github\mollenos\clib\src\string\memmove.c
;	COMDAT _memmove
_TEXT	SEGMENT
_destination$ = 8					; size = 4
_source$ = 12						; size = 4
_count$ = 16						; size = 4
_memmove PROC						; COMDAT

; 11   : {

  00000	55		 push	 ebp
  00001	8b ec		 mov	 ebp, esp

; 12   : 	char *dst = (char *)destination;
; 13   : 	const char *src = (char *)source;

  00003	8b 55 0c	 mov	 edx, DWORD PTR _source$[ebp]
  00006	53		 push	 ebx
  00007	8b 5d 08	 mov	 ebx, DWORD PTR _destination$[ebp]
  0000a	8b c3		 mov	 eax, ebx
  0000c	56		 push	 esi

; 14   : 	long *aligned_dst;
; 15   : 	const long *aligned_src;
; 16   : 
; 17   : 	if (src < dst && dst < src + count)

  0000d	8b 75 10	 mov	 esi, DWORD PTR _count$[ebp]
  00010	57		 push	 edi
  00011	3b d3		 cmp	 edx, ebx
  00013	73 26		 jae	 SHORT $LN11@memmove
  00015	8d 3c 32	 lea	 edi, DWORD PTR [edx+esi]
  00018	3b df		 cmp	 ebx, edi
  0001a	73 1f		 jae	 SHORT $LN11@memmove

; 18   : 	{
; 19   : 		/* Destructive overlap...have to copy backwards */
; 20   : 		src += count;
; 21   : 		dst += count;

  0001c	8d 14 33	 lea	 edx, DWORD PTR [ebx+esi]

; 22   : 		while (count--)

  0001f	85 f6		 test	 esi, esi
  00021	0f 84 7d 00 00
	00		 je	 $LN22@memmove
$LL10@memmove:

; 23   : 	{
; 24   : 		*--dst = *--src;

  00027	8a 4f ff	 mov	 cl, BYTE PTR [edi-1]
  0002a	8d 7f ff	 lea	 edi, DWORD PTR [edi-1]
  0002d	88 4a ff	 mov	 BYTE PTR [edx-1], cl
  00030	8d 52 ff	 lea	 edx, DWORD PTR [edx-1]
  00033	4e		 dec	 esi
  00034	75 f1		 jne	 SHORT $LL10@memmove
  00036	5f		 pop	 edi
  00037	5e		 pop	 esi
  00038	5b		 pop	 ebx

; 66   : }

  00039	5d		 pop	 ebp
  0003a	c3		 ret	 0
$LN11@memmove:

; 25   : 	}
; 26   : 	}
; 27   : 	else
; 28   : 	{
; 29   : 		/* Use optimizing algorithm for a non-destructive copy to closely 
; 30   : 			match memcpy. If the size is small or either SRC or DST is unaligned,
; 31   : 			then punt into the byte copy loop.  This should be rare.  */
; 32   : 		if (!TOO_SMALL(count) && !UNALIGNED (src, dst))

  0003b	83 fe 10	 cmp	 esi, 16			; 00000010H
  0003e	72 50		 jb	 SHORT $LN3@memmove
  00040	8b cb		 mov	 ecx, ebx
  00042	0b ca		 or	 ecx, edx
  00044	f6 c1 03	 test	 cl, 3
  00047	75 47		 jne	 SHORT $LN3@memmove

; 33   : 		{
; 34   : 			aligned_dst = (long*)dst;

  00049	8b fe		 mov	 edi, esi
  0004b	c1 ef 04	 shr	 edi, 4
  0004e	8b ff		 npad	 2
$LL6@memmove:

; 35   : 			aligned_src = (long*)src;
; 36   : 
; 37   : 			/* Copy 4X long words at a time if possible.  */
; 38   : 			while (count >= BIGBLOCKSIZE)
; 39   : 			{
; 40   : 				*aligned_dst++ = *aligned_src++;

  00050	8b 0a		 mov	 ecx, DWORD PTR [edx]

; 41   : 				*aligned_dst++ = *aligned_src++;
; 42   : 				*aligned_dst++ = *aligned_src++;
; 43   : 				*aligned_dst++ = *aligned_src++;
; 44   : 				count -= BIGBLOCKSIZE;

  00052	83 ee 10	 sub	 esi, 16			; 00000010H
  00055	89 08		 mov	 DWORD PTR [eax], ecx
  00057	8b 4a 04	 mov	 ecx, DWORD PTR [edx+4]
  0005a	89 48 04	 mov	 DWORD PTR [eax+4], ecx
  0005d	8b 4a 08	 mov	 ecx, DWORD PTR [edx+8]
  00060	89 48 08	 mov	 DWORD PTR [eax+8], ecx
  00063	8b 4a 0c	 mov	 ecx, DWORD PTR [edx+12]
  00066	83 c2 10	 add	 edx, 16			; 00000010H
  00069	89 48 0c	 mov	 DWORD PTR [eax+12], ecx
  0006c	83 c0 10	 add	 eax, 16			; 00000010H
  0006f	4f		 dec	 edi
  00070	75 de		 jne	 SHORT $LL6@memmove

; 45   : 			}
; 46   : 
; 47   : 			/* Copy one long word at a time if possible.  */
; 48   : 			while (count >= LITTLEBLOCKSIZE)

  00072	83 fe 04	 cmp	 esi, 4
  00075	72 19		 jb	 SHORT $LN3@memmove
  00077	8b fe		 mov	 edi, esi
  00079	c1 ef 02	 shr	 edi, 2
  0007c	8d 64 24 00	 npad	 4
$LL4@memmove:

; 49   : 			{
; 50   : 				*aligned_dst++ = *aligned_src++;

  00080	8b 0a		 mov	 ecx, DWORD PTR [edx]

; 51   : 				count -= LITTLEBLOCKSIZE;

  00082	83 ee 04	 sub	 esi, 4
  00085	89 08		 mov	 DWORD PTR [eax], ecx
  00087	83 c2 04	 add	 edx, 4
  0008a	83 c0 04	 add	 eax, 4
  0008d	4f		 dec	 edi
  0008e	75 f0		 jne	 SHORT $LL4@memmove
$LN3@memmove:

; 52   : 			}
; 53   : 
; 54   : 			/* Pick up any residual with a byte copier.  */
; 55   : 			dst = (char*)aligned_dst;
; 56   : 			src = (char*)aligned_src;
; 57   : 		}
; 58   : 
; 59   : 		while (count--)

  00090	85 f6		 test	 esi, esi
  00092	74 0e		 je	 SHORT $LN32@memmove
  00094	2b d0		 sub	 edx, eax
$LL2@memmove:

; 60   : 		{
; 61   : 			*dst++ = *src++;

  00096	8a 0c 02	 mov	 cl, BYTE PTR [edx+eax]
  00099	8d 40 01	 lea	 eax, DWORD PTR [eax+1]
  0009c	88 48 ff	 mov	 BYTE PTR [eax-1], cl
  0009f	4e		 dec	 esi
  000a0	75 f4		 jne	 SHORT $LL2@memmove
$LN32@memmove:

; 62   : 		}
; 63   : 	}
; 64   : 
; 65   : 	return destination;

  000a2	8b c3		 mov	 eax, ebx
$LN22@memmove:
  000a4	5f		 pop	 edi
  000a5	5e		 pop	 esi
  000a6	5b		 pop	 ebx

; 66   : }

  000a7	5d		 pop	 ebp
  000a8	c3		 ret	 0
_memmove ENDP
_TEXT	ENDS
END
